\chapter{Large value estimates}

The theory of zero density estimates for the Riemann zeta function (and other $L$-functions) rests on the study of what will be called \emph{large value patterns} in this blueprint.

\begin{definition}[Large value pattern]\label{large-pattern-def} A \emph{large value pattern} is a tuple $(N, T, V, (a_n)_{n \in [N,2N]}, J, W)$, where $N > 1$ and $T, V > 0$ are real numbers, $a_n$ is a $1$-bounded sequence on $[N,2N]$, $J$ is an interval of length $T$, and $W$ is a $1$-separated subset of $J$ such that
\begin{equation}\label{V-large}
        \left|\sum_{n \in [N,2N]} a_n n^{-it} \right| \geq V
\end{equation}
for all $t \in W$.

A \emph{Zeta large value pattern} is a large value pattern in which $J = [T,2T]$ and $a_n = 1_I(n)$ for some interval $I \subset [N,2N]$.
\end{definition}

The choice of interval $J$ is not too important for a large value pattern, since one can translate $J$ and $W$ by any shift $t_0$ if we also modulate the coefficients $a_n$ by $n^{it_0}$ to compensate.  However, this modulation freedom is not available for zeta large value patterns, as it destroys the form $a_n = 1_I(n)$ of the coefficients.  The cardinality $|W|$ of $W$ is traditionally called $R$ in the literature.

It is common in the literature to relax the $1$-boundedness hypothesis on $a_n$ slightly, for instance to $a_n \ll T^{o(1)}$, but this does not significantly affect the analysis here.  Similarly, the $1$-separation hypothesis is sometimes strengthened slightly to a $\lambda$-separation hypothesis for some $\lambda = T^{o(1)}$, but again this does not make much difference.  For some estimates, the uniform bound on $a_n$ can be relaxed to an $\ell^2$ hypothesis $\sum_{n \in [N,2N]} |a_n|^2 \ll N$ (and this second moment is traditionally called $G$ in the literature), but we will not study such relaxations systematically here, as they are less relevant for the theory of zero density estimates.

\begin{definition}[Large value exponent]\label{lv-def}\uses{large-pattern-def} Let $1/2 \leq \sigma \leq 1$ and $\tau \geq 0$ be fixed. We define $\LV(\sigma,\tau)$ to be the least fixed quantity for which the following claim is true: whenever $(N,T,V,(a_n)_{n \in [N,2N]},J,W)$ is a large value pattern with $N>1$ unbounded, $T = N^{\tau+o(1)}$, and $V = N^{\sigma+o(1)}$, then
$$ |W| \ll N^{\LV(\sigma,\tau)+o(1)}.$$
\end{definition}

\python{large_values}
\code{Large_Value_Estimate}

One can check that the set of possible candidates for $\LV(\sigma,\tau)$ is closed (by underspill), non-empty, and bounded from below, so $\LV(\sigma,\tau)$ is well-defined as a real number.  As usual, we have an equivalent non-asymptotic definition:

\begin{lemma}[Asymptotic form of large value exponent]\label{lv-asymp}\uses{lv-def} Let $1/2 \leq \sigma \leq 1$, $\tau \geq 0$, and $\rho \geq 0$ be fixed.  Then the following are equivalent:
    \begin{itemize}
    \item[(i)] $\LV(\sigma,\tau) \leq \rho$.
    \item[(ii)] For every (fixed)  $\eps>0$ there exists $C, \delta>0$ such that if $(N,T,V,(a_n)_{n \in [N,2N]},J,W)$ is a large value pattern with $N \geq C$ and $N^{\tau-\delta} \leq T \leq N^{\tau+\delta}$, $N^{\sigma-\delta} \leq V \leq N^{\sigma+\delta}$, then one has
    $$ R \leq C N^{\rho+\eps}.$$
    \end{itemize}
\end{lemma}

The proof of Lemma \ref{lv-asymp} is similar to that of Lemma \ref{beta-asymp}, and is left to the reader.


\begin{lemma}[Basic properties]\label{lv-basic}\uses{lv-def}
    \begin{itemize}
        \item[(i)] (Monotonicity in $\sigma$) For any $\tau \geq 0$, $\sigma \mapsto \LV(\sigma,\tau)$ is upper semicontinuous and monotone non-increasing.
        \item[(ii)] (Huxley subdivision) For any $1/2 \leq \sigma \leq 1$ and $\tau' \geq \tau$ one has
$$ \LV(\sigma,\tau) \leq \LV(\sigma,\tau') \leq \LV(\sigma,\tau) + \tau'-\tau.$$
In particular, $\tau \mapsto \LV(\sigma,\tau)$ is Lipschitz continuous.
        \item[(iii)]  ($\tau=0$ endpoint) One has $\LV(\sigma,0)=0$ for all $1/2 \leq \sigma \leq 1$, and hence by (ii) $0 \leq \LV(\sigma,\tau) \leq \tau$ for all $1/2 \leq \sigma \leq 1$ and $\tau \geq 0$.
    \end{itemize}
\end{lemma}

{\bf TODO: implement Huxley subdivision as a way to transform a large values estimate into a better estimate}

\begin{proof}\uses{auto}
All claims are clear except perhaps for the upper bound
$$ \LV(\sigma,\tau') \leq \LV(\sigma,\tau) + \tau'-\tau,$$
but this follows because any interval of length $N^{\tau'+o(1)}$ may be subdivided into $N^{\tau'-\tau+o(1)}$ intervals of length $N^{\tau+o(1)}$, so on applying Definition \ref{lv-def} to each subinterval and summing (using Lemma \ref{auto} to ensure uniformity), one obtains the claim.
\end{proof}

\begin{lemma}[Lower bound]\label{lv-lower}\uses{lv-def}  For any $1/2 < \sigma \leq 1$ and $\tau \geq 0$, one has $\LV(\sigma, \tau) \geq \min(2 - 2 \sigma,\tau)$, while for $\sigma=1/2$ one has $\LV(\sigma,\tau) = \tau$.
\end{lemma}

\begin{proof}\uses{lv-basic} In view of Lemma \ref{lv-basic}(ii), it suffices to show that $\LV(\sigma, 2-2\sigma) \geq 2-2\sigma$.  By definition, it suffices to find a large value pattern $(N,T,V,(a_n)_{n \in [N,2N]},J,W)$ is a large value pattern with $N$ unbounded, $V=N^{\sigma+o(1)}$, $T = N^{2-2\sigma+o(1)}$, and $|W| \gg N^{2-2\sigma-o(1)}$.

In the endpoint case $\sigma = 1$ one can achieve this by setting $a_n=1$ for all $n$ and taking $W=\{0\}$, so now we assume that $1/2 < \sigma<1$.

We use the probabilistic method.  We divide $[N,2N]$ into $\asymp N^{2-2\sigma}$ intervals $I$ of length $\asymp N^{2\sigma-1}$.  On each interval $I$, we choose $a_n$ to equal some randomly chosen sign $\epsilon_I \in \{-1,+1\}$, with the $\epsilon_I$ chosen independently in $I$.  If $t = o(N^{2-2\sigma})$, then $\sum_{n \in I} a_n n^{-it}$ is equal to $\epsilon_I$ times a deterministic quantity $c_{t,I}$ of magnitude $\asymp N^{2\sigma-1}$ (the point being that the phase $t \log n$ is close to constant in this range).  By the Chernoff bound, we thus see that for any such $t$, $\sum_{n \in [N,2N]} a_n n^{it}$ will have size $\gg N^{(2\sigma-1) + (2-2\sigma)/2} = N^\sigma$ with probability $\gg 1$. By linearity of expectation, we thus see that with positive probability, a $\gg 1$ fraction of integers $t$ with $t = o(N^{2-2\sigma})$ will have this property, giving the claim.

Finally, let $\sigma=1/2$.  In this case we just take each $a_n$ to be a random sign, then by the Chernoff bound one has for each $t$ that $|\sum_{n \in [N,2N]} a_n n^{it}| \asymp N^{1/2}$ with positive probability, which by linearity of expectation as before gives the lower bound $\LV(\sigma,\tau) \geq \tau$, while the upper bound is trivial from Lemma \ref{lv-basic}(iii).
\end{proof}

We conjecturally have a complete description of the function $\LV$:

\begin{conjecture}[Montgomery conjecture]\label{montgomery-conj}\uses{lv-def}  One has
    \begin{equation}\label{mont-conj}
        \LV(\sigma, \tau) \leq 2 - 2 \sigma
    \end{equation}
     for all fixed $1/2 < \sigma \leq 1$ and $\tau \geq 0$. Equivalently (by Lemma \ref{lv-basic}(ii), (iii) and Lemma \ref{lv-lower}), one has $\LV(\sigma, \tau) = \min(2 - 2 \sigma,\tau)$ for all $1/2 < \sigma \leq 1$ and $\tau \geq 0$.
\end{conjecture}

\python{large_values}
\code{montgomery_conjecture}

We refer to \cite{bourgain_montgomery_1991} for further discussion of this conjecture, including some counterexamples to strong versions of the conjecture in which certain epsilon losses are omitted.  In view of this conjecture, we do not expect any further lower bounds on $\LV(\sigma,\tau)$ to be proven, and the literature is instead focused on upper bounds.

The following application of subdivision is useful:

\begin{lemma}[Subdivision and the Montgomery conjecture]\label{montgomery-subdivide}\uses{montgomery-conj}  If $\sigma$ is fixed, and the Montgomery conjecture holds for all fixed $\tau < \tau_0$, then
\begin{equation}\label{lvt-opt}
    \LV(\sigma, \tau) \leq \max( 2 - 2 \sigma, \tau - \tau_0 + 2 - 2\sigma)
\end{equation}
for all fixed $\tau \geq 0$.
\end{lemma}

\begin{proof}\uses{lv-basic}
Clear from Lemma \ref{lv-basic}(ii).
\end{proof}


The following basic property of $\LV(\sigma,\tau)$ is extremely useful in applications:

\begin{lemma}[Raising to a power]\label{power-lemma}\uses{lv-def}  For any $1/2 \leq \sigma \leq 1$, $\tau \geq 0$, and natural number $k$, one has
    $$ \LV(\sigma, k\tau) \leq k \LV(\sigma, \tau).$$
\end{lemma}

\python{large_values}
\code{raise_to_power_hypothesis()}

\begin{proof} Let  $(N,T,V,(a_n)_{n \in [N,2N]},J,W)$ be a large value pattern with $T = N^{k\tau+o(1)}$ and $V = N^{\sigma+o(1)}$, Raising \eqref{V-large} the $k^{\mathrm{th}}$ power, we conclude that
$$ \left|\sum_{n \in [N^k,2^kN^k]} b_n n^{-it} \right| \geq V^k$$
for all $t \in W$, where $b_n$ is the Dirichlet convolution of $k$ copies of $a_n$, and thus is bounded by $N^{o(1)}$ thanks to divisor bounds.  Subdividing $[N^k, 2^k N^k]$ into $k$ intervals of the form $[N',2N']$ for $N' \asymp N^k$ and applying Definition \ref{lv-def} (with $N, T, V$ replaced by $N', T, V^k$) we conclude that
$$ |W| \ll N^{k \LV(\sigma,\tau) + o(1)}$$
and the claim then follows.
\end{proof}

\section{Known upper bounds on \texorpdfstring{$\LV(\sigma,\tau)$}{LV(sigma,tau)}}

Similarly to upper bounds on $\beta(\alpha)$, upper bounds on $\LV(\sigma,\tau)$ in the literature (also known as \emph{large value theorems}) tend to be piecewise linear functions of $\sigma$ and $\tau$.  Such bounds often tend to be convex initially (i.e., the maximum of several linear functions), but when one combines multiple large value theorems together, the bound is usually neither convex nor concave, though it often remains piecewise linear, and continuous in $\tau$ (though jump discontinuities in $\sigma$ are possible).

Listed below are some examples of such bounds.

\begin{theorem}[$L^2$ mean value theorem]\label{l2-mvt}\uses{lv-def} For any fixed $1/2 \leq \sigma \leq 1$ and $\tau\geq 0$ one has
    $$ \LV(\sigma,\tau) \leq \max( 2-2\sigma, 1 + \tau - 2 \sigma).$$
In particular, the Montgomery conjecture \eqref{mont-conj} holds for $\tau \leq 1$.
\end{theorem}

\python{large_values}
\code{large_value_estimate_L2}

\begin{proof}
LEt $(N,T,V,(a_n)_{n \in [N,2N]},J,W)$ be a large value pattern with $T = N^{\tau + o(1)}$, $V = N^{\sigma + o(1)}$. Applying \cite[Theorem~9.4]{ik} (with $N$, $T$ replaced with $2N$, $2T$ respectively and taking $a_n = 0$ for $n < N$) one has
\[
|W|V^2 \le \sum_{t \in W} \left|\sum_{N \le n \le 2N} a_n n^{-it}\right|^2 \ll N^{1 + o(1)}(T + N)
\]
from which the result follows.
\end{proof}

\begin{theorem}[Montgomery large values theorem]\label{montgomery-lv}\uses{beta-def, lv-def} If $1/2 \leq \sigma \leq 1$ and $\tau \geq 0$ is such that
\begin{equation}\label{tab}
\sup_{1 \leq \tau' \leq \tau} \beta(1/\tau') \tau' < 2\sigma - 1
\end{equation}
(this condition is vacuous for $\tau < 1$) then the Montgomery conjecture \eqref{mont-conj} holds for this choice of parameters.
\end{theorem}

For a stronger version of this inequality, see Lemma \ref{hl-improv}.

\begin{proof}\uses{beta-triv}  Set $\rho := \LV(\sigma,\tau)$; we may assume without loss of generality that $\rho \geq 0$.  Then by Definition \ref{lv-def}, we can find a large value pattern $(N,T,V,(a_n)_{n \in [N,2N]},J,W)$  with $N > 1$ unbounded, $T = N^{\tau + o(1)}$, $V = N^{\sigma + o(1)}$, and $|W| = N^{\rho+o(1)}$.  From \eqref{V-large} we have
$$ \sum_{t \in W} \left|\sum_{n \in [N,2N]} a_n n^{it} \right| \geq |W|V$$
hence for some $1$-bounded coefficients $c_t$
$$ \left|\sum_{t \in W} c_t \sum_{n \in [N,2N]} a_n n^{it} \right| \geq |W|V$$
We apply the Hal\'asz argument. Interchanging the summations and applying Cauchy--Schwarz, we conclude that
$$ |W|V \leq N^{1/2} \left|\sum_{t, t' \in W} c_t \overline{c_{t'}} \sum_{n \in [N,2N]} n^{i(t-t')} \right|^{1/2}$$
hence on squaring and using the triangle inequality
$$ N^{2\rho} \ll N^{1-2\sigma+o(1)} \sum_{t,t' \in W} \left|\sum_{n \in [N,2N]} n^{i(t-t')} \right|.$$
In the case $|t - t'| \leq N^{1-\eps}$ for any fixed $\eps>0$, one can use Lemma \ref{beta-triv} to obtain the bound
$$ \sum_{n \in [N,2N]} n^{i(t-t')} \ll N^{o(1)} \frac{N}{1 + |t - t'|}.$$
The total contribution of this case can then be bounded by $N^{1+o(1)} R = N^{1+\rho+o(1)}$, thanks to the $1$-separation.
In the remaining cases $|t - t'| \geq N^{1-o(1)}$, we use Definition \ref{beta-def} to see that
$$ \sum_{n \in [N,2N]} n^{i(t-t')} \ll N^{\sup_{1 \leq \tau' \leq \tau} \beta(1/\tau') \tau' + o(1)}$$
and thus
$$ N^{2\rho} \ll N^{2-2\sigma+\rho+o(1)} + N^{2\rho + 1-2\sigma+\sup_{1 \leq \tau' \leq \tau} \beta(1/\tau') \tau' + o(1)}.$$
By hypothesis, the second term on the right-hand side is asymptotically smaller than the left-hand side, and so we obtain $\rho \leq 2-2\sigma$ as required.
\end{proof}

\begin{corollary}[Converting an exponent pair to a large values theorem]\label{exp-lv}\uses{exp-pair-def, lv-def}  If $(k,\ell)$ is an exponent pair, and $1/2 \leq \sigma \leq 1$, and $\tau \geq 0$ are fixed, then
$$\LV(\sigma,\tau) \leq \max\left( 2-2\sigma, 2 - 2\sigma + \tau - \frac{2\sigma+k-\ell-1}{k} \right).$$
In particular, the Montgomery conjecture holds for $\tau \leq \frac{2\sigma+k-\ell-1}{k}$.
\end{corollary}

One can also obtain a similar implication starting from a bound on $\mu$: see Lemma \ref{mu-lv}.

\begin{proof}\uses{beta-duality, montgomery-lv, montgomery-subdivide}  By Lemma \ref{montgomery-subdivide} it suffices to prove the latter claim.  From Lemma \ref{beta-duality} one has
    $\beta(1/\tau') \tau' \leq k \tau' + (\ell-k)$
and so the condition \eqref{tab} holds whenever
$$ \tau < \frac{2\sigma+k-\ell-1}{k}.$$
The claim follows.
\end{proof}

\begin{theorem}[Huxley large values theorem]\label{huxley-lv}\cite[Equation~(2.9)]{Huxley}\uses{lv-def} Let $1/2 \leq \sigma \leq 1$ and $\tau \geq 0$ be fixed.  Then one has
    $$ \LV(\sigma,\tau) \leq \max( 2-2\sigma, 4 + \tau - 6 \sigma).$$
    In particular, one has the Montgomery conjecture for $\tau \leq 4 \sigma - 2$.
\end{theorem}

\literature
\code{add_huxley_large_values_estimate()}

\begin{proof}\uses{exp-lv, vdc-class}  Apply Corollary \ref{exp-lv} with the pair $(k,\ell) = (1/2,1/2)$ from Lemma \ref{vdc-class}.
\end{proof}


\begin{theorem}[Heath-Brown large values theorem, preliminary form]\label{heath_brown-lv-prelim}\uses{lv-def} Let $1/2 \leq \sigma \leq 1$ and $\tau \geq 0$ be fixed.  If $\LV(\sigma, \tau) \le \rho$ then
    \[
    \LV(\sigma, \tau) \le \max\left(2 - 2\sigma, \frac{11}{12}\rho + \frac{3}{2} + \frac{\tau}{6} - 2\sigma\right)
    \]
\end{theorem}

\begin{proof}
    Follows from \cite[Lemma~1]{heathbrown_zero_1979}.
\end{proof}

\begin{theorem}[Heath-Brown large values theorem, optimized]\label{hb-opt}\uses{lv-def} Let $1/2 \leq \sigma \leq 1$ and $\tau \geq 0$ be fixed.   One has
    $$ \LV(\sigma,\tau) \leq \max( 2-2\sigma, 10 + \tau - 13 \sigma).$$
In particular, the Montgomery conjecture holds for $\tau \leq 11 \sigma - 8$.
\end{theorem}


\literature
\code{add_heath_brown_large_values_estimate()}

\begin{proof}\uses{heath_brown-lv-prelim, montgomery-subdivide}  By Lemma \ref{montgomery-subdivide} it suffices to show that $\LV(\sigma,\tau) \leq 2-2\sigma$ for $\tau \leq 11\sigma-8$.  From the previous theorem, and setting $\rho = \LV(\sigma,\tau)$, we have either
$$ \LV(\sigma,\tau) \leq 2-2\sigma$$
or
$$ \LV(\sigma,\tau) \leq \frac{11}{12}\LV(\sigma,\tau) + \frac{3}{2} + \frac{\tau}{6} - 2\sigma.$$
The latter bound can be rearranged as
$$ \LV(\sigma,\tau) \leq 2\tau + 18 - 24\sigma$$
and thus
$$ \LV(\sigma,\tau) \leq \min( 2-2\sigma, 2\tau + 18 - 24\sigma),$$
and the claim follows.  (See also the arguments in the first paragraph of \cite[p. 226]{heathbrown_zero_1979}.)
\end{proof}


\begin{lemma}[Second Heath-Brown large values theorem]\label{hb-lvt-2}\uses{lv-def} If $3/4 < \sigma \leq 1$ and $\tau \geq 0$ are fixed, then
    $$ \LV(\sigma,\tau) \leq \max( 2-2\sigma, k\tau + k(2-4\sigma), 2\tau/3 + k(12-16\sigma)/3 )$$
    for any positive integer $k$.
    \end{lemma}

\begin{proof} Let $(N,T,V,(a_n)_{n \in [N,2N]},J,W)$ be a large value pattern with $N \geq 1$ be unbounded, $T = N^{\tau + o(1)}$,  $V = N^{\sigma + o(1)}$, and $|W| = N^{\rho+o(1)}$. By \cite[Lemma~6]{heathbrown_large_1979} we have
    $$ (|W| V)^2 \ll T^{o(1)}( |W|N + |W|^2 N^{1/2} + |W|^{2-1/2k} T^{1/2} + |W|^{2-3/8k} N^{1/2} T^{1/4k}) N$$
and thus
$$ 2(\rho + \sigma) \leq \max( \rho+1, 2\rho+1/2, (2-1/2k)\rho + \tau/2, (2-3/8k)\rho + 1/2 + \tau/4k).$$
Since $\sigma > 3/4$, we can delete the second term $2\rho+1/2$ on the right-hand side. Solving for $\rho$, we conclude that
$$ \rho \leq \max( 2-2\sigma, k\tau + k(2-4\sigma), 2\tau/3 + k(12-16\sigma)/3 ),$$
and taking suprema in $\rho$, we obtain the claim.
\end{proof}

\begin{theorem}[Jutila large values theorem]\label{jutila-lvt}\uses{lv-def}  For any integer $k \geq 1$, one has
$$ \LV(\sigma,\tau) \leq \max(2-2\sigma, \tau + (4-2/k) - (6-2/k)\sigma, \tau + (6-8\sigma)k).$$
Thus for instance with $k=2$ we have
$$ \LV(\sigma,\tau) \leq \max(2-2\sigma, \tau + 3 - 5\sigma, \tau + 12-16\sigma)$$
and with $k=3$ we have
$$ \LV(\sigma,\tau) \leq \max(2-2\sigma, \tau + \frac{10-16\sigma}{3}, \tau + 18-24\sigma).$$
In particular, the Montgomery conjecture holds for
$$ \tau \leq \min( (4-2/k)\sigma - (2-2/k), (8k-2)\sigma - 6k + 2).$$
\end{theorem}

\literature
\code{add_jutila_large_values_estimate(Constants.LARGE_VALUES_TRUNCATION)}

\begin{proof} See \cite[(1.4)]{jutila_zero_density_1977} (setting $V = N^{\sigma+o(1)}$, $T = N^{\tau+o(1)}$, and $G \leq N$).  We remark that this form is an optimized form of the inequality after (3.2) in Jutila's paper, which in our notation would read that
$$ 2\LV(\sigma,\tau) + 2\sigma \leq \max \left(2 + \rho, \frac{3}{2} + \left(2 - \frac{1}{k}\right)\rho + \rho + \frac{1}{2k}\max\left(k(\tau-1), \frac{\rho+\tau}{2}\right), 2\rho + 1\right)$$
whenever $\LV(\sigma,\tau) \leq \rho$.  The optimization follows from Lemma \ref{montgomery-subdivide} and routine calculations.
\end{proof}

Some additional large values theorems are established in Chapter \ref{energy-chapter}.
