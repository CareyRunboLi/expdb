\chapter{Distribution of primes: long ranges}
\label{chap:prime_counting_function}

Let $\Lambda(n)$ denote the von Mangoldt function, i.e. $\Lambda(n) = \log p$ if $n = p^m$ where p is prime and $m$ is a positive integer, and $\Lambda(n) = 0$ otherwise. 

\begin{definition}
For all $x \ge 1$ define the Chebyshev prime counting functions $\psi(x)$, $\theta(x)$ and $\pi(x)$ as
\[
\psi(x) := \sum_{n \le x}\Lambda(n),\qquad \theta(x) := \sum_{p \le x}\log p,\qquad \pi(x) := \sum_{p \le x}1
\]
where the first sum is over positive integers $n$ and the last two sums are over primes $p$.
\end{definition}

These functions, particularly $\pi(x)$, are central to number theory because they measure the distribution of prime numbers among the integers. A well-known result is the prime number theorem.

\begin{theorem}[Prime number theorem]
As $x \to \infty$, 
\[
\pi(x) \sim \frac{x}{\log x} \sim \operatorname{li}(x) := \int_2^{\infty}\frac{dt}{\log t}.
\]
\end{theorem}

The following are equivalent formulations of the prime number theorem.

\begin{theorem}[Prime number theorem, alternative formulations]
As $x \to \infty$, one has $\psi(x) \sim x$ and $\theta(x) \sim x$.
\end{theorem}

\section{Error bounds for prime counting functions}
In addition to their asymptotic behaviour, various bounds on the deviation from their respective asymptotics are known. The current best-known error bounds are derived from zero-free regions of the Riemann zeta function $\zeta(s)$. The relation between zeroes of $\zeta(s)$ and error bounds for prime counting functions are illustrated through von Mangoldt's explicit formula: for all non-integer $x > 0$, one has
\[
\psi(x) = x - \sum_{\rho}\frac{x^\rho}{\rho} - \log 2\pi - \frac{1}{2}\log(1 - x^{-2}),
\]
where $\rho$ runs through all non-trivial zeroes of $\zeta(s)$.

\begin{theorem}[Korobov--Vinogradov estimate]
There exists a positive constant $A$, such that
\begin{align*}
\psi(x) - x, \; \theta(x) - x, \; \pi(x) - \operatorname{li}(x) \ll x\exp\left(-A\frac{(\log x)^{3/5}}{(\log\log x)^{1/5}}\right).
\end{align*}
\end{theorem}

\Cref{prime-error-table} lists the historical progression on estimates of $\pi(x)$.

\begin{table}[ht]
    \caption{Historical estimates of $\pi(x)$, for $x$ sufficiently large.}
    \centering
    \renewcommand{\arraystretch}{2.2}
    \begin{tabular}{|c|c|}
    \hline
    Reference & Estimate of $\pi(x)$\\
    \hline
    Chebyshev & $c_1 \dfrac{x}{\log x} \leq \pi(x) \leq c_2 \dfrac{x}{\log x}$ for some constants $0 < c_1 < 1 < c_2$, i.e. $\pi(x) \asymp \dfrac{x}{\log x}$\\
    \hline
    de la Vall\'{e}e Poussin \cite{de_la_vallee_poussin_recherches_1896}, Hadamard \cite{hadamard_distribution_1896} & $\pi(x) = \dfrac{x}{\log x}(1 + o(1))$ i.e. $\pi(x) \sim \dfrac{x}{\log x}$\\
    \hline
    de la Vall\'{e}e Poussin \cite{de_la_vallee_poussin_fonction_1899} & $\pi(x) = \operatorname{li}(x) + O(x\exp(-A\sqrt{\log x}))$ for some $A > 0$\\
    \hline
    Littlewood \cite{littlewood_researches_1922} & $\pi(x) = \operatorname{li}(x) + O(x\exp(-A\sqrt{\log x\log\log x}))$ for some $A > 0$\\
    \hline 
    Korobov, Vinogradov \cite{vinogradov_eine_1958} & $\pi(x) = \operatorname{li}(x) + O\left(x\exp\left(-\dfrac{A(\log x)^{3/5}}{(\log\log x)^{1/5}}\right)\right)$ for some $A > 0$\\
    \hline
    \end{tabular}\label{prime-error-table}
\end{table}

Under the Riemann hypothesis, stronger error bounds are known. 
\begin{theorem}[\cite{koch_sur_1901}]
If the Riemann hypothesis is true, then
\[
\psi(x) - x,\; \theta(x) - x \ll x^{1/2}(\log x)^2,\qquad \pi(x) - \operatorname{li}(x) \ll x^{1/2}\log x.
\]
\end{theorem}

Slightly sharper estimates are possible if one assumes even stronger hypotheses. 
\begin{theorem}[Heath-Brown \cite{heathbrown_gaps_1982}]
Assume that the Riemann hypothesis is true. Furthermore, assume that 
\[
F_T(X) := \sum_{0 < \gamma_1, \gamma_2 \le T}\frac{e((\gamma_1 - \gamma_2)X)}{1 + (\gamma_1 - \gamma_2)^2/4} = o(T^2 (\log T)^2)
\]
where the sum is over the imaginary parts of all pairs of non-trivial zeroes of $\zeta(s)$. Then
\[
\psi(x) = x + o(x^{1/2}(\log x)^2).
\]
\end{theorem}
The same result was previously proved (assuming stronger hypotheses) by Gallagher--Mueller \cite{gallagher_primes_1978} and later by Mueller. 

\section{Relation to zero free region of zeta}

\begin{lemma}[Relation to zero free regions]\label{zero_free_to_pnt}\cite{ingham_distribution_1990}
Suppose $\zeta(\sigma + it) \ne 0$ for $\sigma \ge 1 - \eta(t)$ where $\eta(t)$ is a positive and decreasing function. Then
\[
\psi(x) - x \ll x \exp\left(-A \omega(x) \right)\qquad (x \to \infty)
\]
for an absolute constant $A > 0$, where 
\[
\omega(x) := \inf_{t \ge 1}(\eta (t) \log x + \log t).
\]
\end{lemma}

Applying \Cref{zero_free_to_pnt}, one obtains the error term estimates in the prime number theorem given in Table \ref{zero-free-pnt-table}.   

\begin{table}[ht]
    \def\arraystretch{2.5}
    \centering
    \caption{Zero free regions for $\zeta(s)$, along with the bound on $\psi(x) - x$ that they imply. Here $A$ represents an absolute, positive constant, which may be different at each occurrence.}
    \begin{tabular}{|c|c|c|}
    \hline
    Reference & Zero free region & Bound on $(\psi(x) - x)/x$ \\
    \hline
    \Cref{zfr-classical} & $\sigma \ge 1 - \dfrac{A}{\log t}$ & $\exp(-A(\log x)^{1/2})$ \\
    \hline 
    \Cref{zfr-littlewood} & $\sigma \ge 1 - \dfrac{A\log\log t}{\log t}$ & $\exp(-A(\log x \log\log x)^{1/2})$\\
    \hline 
    \Cref{zfr-chudakov} & $\sigma \ge 1 - \dfrac{A}{(\log t)^{3/4 + o(1)}}$ & $\exp(-A(\log x)^{4/7 + o(1)})$\\
    \hline 
    \Cref{zfr-vk} & $\sigma \ge 1 - \dfrac{A}{(\log t)^{2/3}(\log\log t)^{1/3}}$ & $\exp\left(-A\dfrac{(\log x)^{3/5}}{(\log\log x)^{1/5}}\right)$\\
    \hline 
    \end{tabular}
\label{zero-free-pnt-table}
\end{table}

The following type of converse statement is also known.

\begin{theorem}[\cite{turan_new_1984} Theorem 40.1] If for some $0 < \alpha \le 1$ one has
\[
\psi(x) - x \ll x \exp(-A(\log x)^{1/(1 + \alpha)})\qquad (x \to \infty)
\]
then $\zeta(\sigma + it) \ne 0$ for $t$ sufficiently large and
\[
\sigma > 1 - \frac{A}{(\log t)^{\alpha}}.
\]
Here $A$ denotes an absolute positive constant, not necessarily the same at each occurrence. 
\end{theorem}


\section{Omega results}

In the opposite direction, it is known that 
\begin{theorem}[Schmidt \cite{schmidt_uber_1903}]
As $x \to \infty$,
\[
\psi(x) = x + \Omega(x^{1/2}).
\]
\end{theorem}
This can be improved slightly conditioned on the Riemann hypothesis.
\begin{theorem}[Littlewood \cite{littlewood_sur_1914}]
If the Riemann hypothesis is true, then as $x \to \infty$,
\[
|\pi(x) - \operatorname{li}(x)| = \Omega\left(x^{1/2}\frac{\log\log\log x}{\log x}\right).
\]
\end{theorem}

Furthermore it is also known that
\begin{theorem}[Grosswald \cite{grosswald_sur_1965}]
If 
\[
\theta = \sup_{\rho: \zeta(\rho) = 0}\Re \rho > 1/2
\]
then as $x \to \infty$,
\[
\psi(x) = x + \Omega(x^{\theta}).
\]
\end{theorem}

